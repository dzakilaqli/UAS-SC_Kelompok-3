# -*- coding: utf-8 -*-
"""CNN Vegetables Python

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19peajCAn9-wkHs2uS9OOHpdYaCoVgRNG

##**KLASIFIKASI GAMBAR SAYURAN MENGGUNAKAN CONVOLUTIONAL NEURAL NETWORK (CNN)**##
---
Anggota Kelompok :
1. Muhamad Aksyal Faiz Destian	(2210631250019)
2. Farrel Zaindri Althaf	(2210631250050)
3. Muhammad Dzakil Aqli	(2210631250062)
---
Convolutional Neural Network (CNN) adalah salah satu jenis deep learning yang populer untuk pemodelan klasifikasi gambar. CNN sangat efektif dalam mengenali objek pada gambar karena model dapat mempelajari fitur-fitur dari data gambar. CNN telah digunakan pada banyak aplikasi, seperti pengenalan wajah, pengenalan karakter tulisan tangan, serta klasifikasi objek.

Pada project ini dataset yang digunakan adalah data gambar dari 15 jenis sayuran. Dataset ini sudah tersusun dengan struktur yang rapi sehingga tidak diperlukan banyak pengaturan. Di dalam direktori data juga sudah tersusun dalam 3 subdirektori terpisah untuk data latih, validasi maupun data uji. Pada masing-masing subdirektori tersebut sudah terdapat 15 subdirektori berdasarkan 15 jenis sayuran.

# IMPORT DATASET
"""

import kagglehub
misrakahmed_vegetable_image_dataset_path = kagglehub.dataset_download('misrakahmed/vegetable-image-dataset')

print('Data source import complete.')

"""## PENYIAPAN DATA GAMBAR"""

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

"""## 1.1. Penyiapan direktori dan Data"""

# inisiasi path data gambar
images_path = "/kaggle/input/vegetable-image-dataset/Vegetable Images"
train_path = "/train"
val_path = "/validation"
test_path = "/test"

# Check if the directory exists before scanning
full_train_path = images_path + train_path
if not os.path.isdir(full_train_path):
    print(f"Error: Directory not found - {full_train_path}")
else:
    subdirectories = [f.name for f in os.scandir(full_train_path) if f.is_dir()]

    print("Daftar nama subdirektori:")
    for subdir in subdirectories:
        print(subdir)

# fungsi untuk menampilkan gambar secara acak pada grid n_row x n_col
def view_random_image(data_dir, class_dir, n_row=1, n_col=1):

    # menentukan direktori gambar
    target_dir = data_dir + "/" + class_dir + "/"

    # memilih sebanyak n_row*n_col gambar secara acak
    rand_images = random.sample(os.listdir(target_dir), n_row*n_col)

    fig, axs = plt.subplots(n_row, n_col)

    # menampilkan gambar dalam bentuk grid ukuran n_row*n_col
    for i, ax in enumerate(axs.flat):
        img = mpimg.imread(target_dir + rand_images[i])
        ax.imshow(img)
        ax.set_title(f"{class_dir} {i+1}\n{img.shape}")
        ax.axis("off")

    plt.tight_layout()
    plt.show()


# menampilkan contoh beberapa gambar acak dari direktori train
# Pass the full training path to the function
view_random_image(full_train_path, "Bean", 1, 3)
view_random_image(full_train_path, "Cucumber", 1, 3)

"""## 1.2. Image Data Generator"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

tf.random.set_seed(42)

# pengaturan data training dengan scaling images saja
# train_datagen = ImageDataGenerator(rescale=1.0 / 255)

# pengaturan data training dengan berbagai augmentasi
train_datagen = ImageDataGenerator(rescale=1.0 / 255,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

# pengaturan data validasi selama pelatihan
val_datagen = ImageDataGenerator(rescale=1.0 /255)

# pengaturan data uji untuk evaluasi model
test_datagen = ImageDataGenerator(rescale=1.0 /255)

# menentukan ukuran gambar untuk proses pelatihan
img_size = (224, 224)

# menyiapkan data training dengan pengaturan yang sudah ditentukan
train_data = train_datagen.flow_from_directory(images_path + train_path,
                                               target_size=img_size,
                                               batch_size=32,
                                               class_mode='categorical',
                                               seed=42)

 # menyiapkan data validasi
val_data = val_datagen.flow_from_directory(images_path + val_path,
                                           target_size=img_size,
                                           batch_size=32,
                                           class_mode='categorical',
                                           seed=42)

# menyiapkan data uji
test_data = test_datagen.flow_from_directory(images_path + test_path,
                                             target_size=img_size,
                                             batch_size=32,
                                             class_mode='categorical',
                                             shuffle=False)

# menampilkan jumlah batch pada data train
print(f"Jumlah batch (training): {len(train_data)}")

# mengambil batch 1 data train
batch_1_train = train_data[0]

# setiap batch tersimpan dalam bentuk tupple
# elemen pertama menyimpan data piksel dari 32 gambar pada batch 1
batch_1_train_data = train_data[0][0]

# elemen kedua  menyimpan data label dari 32 gambar pada batch 1
batch_1_train_label = train_data[0][1]

# ukuran batch = 32 (sesuai pengaturan)
print(f"Jumlah gambar pada batch 1: {len(batch_1_train_data)}")
print(f"Jumlah label pada batch 1: {len(batch_1_train_label)}")

# mengambil gambar 1 pada batch 1 data training
image_1_batch_1_train_data = train_data[0][0][0]

# mengambil label (kelas) gambar 1 pada batch 1 data training
image_1_batch_1_train_label = train_data[0][1][0]

# menampilkan data gambar 1 : (224, 224, 3)
print(f"\nBatch 1 Gambar 1 train (data):\n{image_1_batch_1_train_data}")

# menampilkan data label (kelas) gambar 1 pada batch 1 data training
print(f"\nBatch 1 Gambar 1 train (Label):\n{image_1_batch_1_train_label}")

"""## MODEL CNN

## 2.1. Mebuat Model
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D
from tensorflow.keras.optimizers import Adam

# Cek apakah GPU terdeteksi
if tf.test.gpu_device_name():
    print(f"GPU detected: {tf.test.gpu_device_name()}")
else:
    print("No GPU detected")

tf.random.set_seed(42)

model_1 = Sequential()

model_1.add(
    Conv2D(filters=20, kernel_size=(3, 3), activation="relu", input_shape=(224, 224, 3))
)
model_1.add(Conv2D(20, (3, 3), activation="relu"))
model_1.add(MaxPool2D((2, 2), padding="valid"))

model_1.add(Conv2D(50, (3, 3), activation="relu"))
model_1.add(Conv2D(50, (3, 3), activation="relu"))
model_1.add(MaxPool2D((2, 2)))

model_1.add(Flatten())
model_1.add(Dense(15, activation="softmax"))  # number of neurons have to match number of class

# Compile the model
model_1.compile(
    loss="categorical_crossentropy",
    optimizer=Adam(),
    metrics=["accuracy"],
)

# Fit the model
history_1 = model_1.fit(
        train_data,
        validation_data=val_data,
        epochs=10,
)

"""## 2.2. Menyimpan dan Memuat Model"""

from tensorflow.keras.models import load_model

model_1.save("model_10_epochs.keras")

my_model_1 = load_model("model_10_epochs.keras")

"""## 2.3. Evaluasi dan Prediksi"""

print(model_1.evaluate(test_data))

predictions = model_1.predict(test_data)
print(predictions.round(2))

import seaborn as sns
import numpy as np
from sklearn.metrics import confusion_matrix

# Mengkonversi peluang prediksi menjadi kelas
y_pred_class = np.argmax(predictions, axis=1)

# Mendapatkan kelas sebenarnya dari test_data
y_true_class = test_data.classes

# membuat confusion matrix
conf_matrix = confusion_matrix(y_true_class, y_pred_class)

# menampilkan confusion matrix dalam bentuk heatmap
fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(
    conf_matrix,
    annot=True,
    annot_kws={"fontsize": 10},
    fmt=".0f",
    linewidth=0.5,
    square=True,
)
plt.show()

"""## MEMBUAT MODEL (DENGAN PRETRAINED MODEL)

## 3.1. Model CNN dengan Model Dasar VGG16
"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

# Membuat base model menggunakan VGG16 pre-trained weights
base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))

# Membuat model CNN
model_2 = Sequential()

# Menambahkan base model ke model CNN
model_2.add(base_model)

# Menambahkan layer dense untuk klasifikasi
model_2.add(Flatten())
model_2.add(Dense(128, activation='relu'))
model_2.add(Dense(15, activation='softmax'))

# Membekukan parameter pada base model
base_model.trainable = False

# Compile model
model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Melihat ringkasan model
model_2.summary()

# Fit the model
history_2 = model_2.fit(
        train_data,
        validation_data=val_data,
        epochs=5,
)

# menyimpan model hasil pelatihan
model_2.save("model_with_vgg16.keras")

# memuat model hasil pelatihan
my_model_2 = load_model("model_with_vgg16.keras")

"""## 3.3. Evaluasi dan Prediksi"""

my_model_2.evaluate(test_data)

predictions = my_model_2.predict(test_data)
# Mengkonversi prediksi menjadi label kelas
y_pred_class = np.argmax(predictions, axis=1)
y_true_class = test_data.classes


fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(
    confusion_matrix(y_true_class, y_pred_class),
    annot=True,
    annot_kws={"fontsize": 10},
    fmt=".0f",
    linewidth=0.5,
    square=True,
)
plt.show()